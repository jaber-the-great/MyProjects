## Research:
- [x] Why we measure toy benchmark program?
- [x] Compare the performance of different programming languages on the provided toy benchmarks
 

## Development and code
- [x] Develop several new toy programs for benchmarking
  - [x] Try making toy programs related to data science
- [x] Make sure that toy programs are implemented similarly in all of the languages and have the same runtime complexity: Big O notation etc
- [x] Select programs from benchmark website for MATLAB, R, Python that are most data analytics/science-oriented
  - [ ] Might need to insetigate other benchmark websites, current one does not seem to support MATLAB/R
- [ ] Fill out the vminit templates for fib and simple object codes
- [x] Develop 4 other programs for the project related to:
  - [x] Statistical analysis
  - [x] Data cleaning
  - [x] Matrix multiplication and array slicing 
  - [x] Machine learning (Regression of classification).
    - [ ] Should we include plotting or not ? 

## Benchmarking
- [x] Run each of the toy programs 10 times on the same system
- [x] Make sure the system has similar background workload while running all of the tests with different languages
- [x] Run all of the tests at the same time !!!
- [x] Analyze the derived data
- [x] Plot the corresponding graphs for better analysis
- [x] Leverage multi-core and single core systems for test

## Documentation 
- [x] Comment and document each part of the toy programs
- [x] Document the decision making step for designing the toy programs
- [x] Find the clues for different benchmark time 
- [x] Cite everything which is used in the project 